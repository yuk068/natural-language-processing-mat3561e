{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpkkrr15vobK"
      },
      "source": [
        "# Lab 5: Phân loại Văn bản với Mạng Nơ-ron Hồi quy (RNN/LSTM)"
      ],
      "id": "Zpkkrr15vobK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTaFXv30vobN"
      },
      "source": [
        "## Bước 0: Thiết lập Môi trường và Tải Dữ liệu"
      ],
      "id": "dTaFXv30vobN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGmmE6QnvobO",
        "outputId": "475ad497-142c-4721-b9b6-59fda2b47e09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "# Import các thư viện cần thiết\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tarfile\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "# SKLearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "# Gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# TensorFlow / Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")"
      ],
      "id": "RGmmE6QnvobO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgdfMQ_qvobP",
        "outputId": "c8e2bc56-8153-48ba-8cc5-c5e32ea92d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (8954, 2)\n",
            "Validation shape: (1076, 2)\n",
            "Test shape: (1076, 2)\n",
            "\n",
            "Train data head:\n",
            "                                                text     category\n",
            "0                what alarms do i have set right now  alarm_query\n",
            "1                    checkout today alarm of meeting  alarm_query\n",
            "2                              report alarm settings  alarm_query\n",
            "3  see see for me the alarms that you have set to...  alarm_query\n",
            "4                       is there an alarm for ten am  alarm_query\n"
          ]
        }
      ],
      "source": [
        "# Đọc dữ liệu bằng Pandas\n",
        "train_file = '/content/train.csv'\n",
        "val_file = '/content/val.csv'\n",
        "test_file = '/content/test.csv'\n",
        "\n",
        "try:\n",
        "    df_train = pd.read_csv(train_file, sep=',', header=None, names=['text', 'category'], skiprows=1)\n",
        "    df_val = pd.read_csv(val_file, sep=',', header=None, names=['text', 'category'], skiprows=1)\n",
        "    df_test = pd.read_csv(test_file, sep=',', header=None, names=['text', 'category'], skiprows=1)\n",
        "\n",
        "    print(\"Train shape:\", df_train.shape)\n",
        "    print(\"Validation shape:\", df_val.shape)\n",
        "    print(\"Test shape:\", df_test.shape)\n",
        "\n",
        "    print(\"\\nTrain data head:\")\n",
        "    print(df_train.head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Lỗi: Không tìm thấy file CSV. Vui lòng kiểm tra lại đường dẫn và kết quả giải nén.\")"
      ],
      "id": "FgdfMQ_qvobP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyzYcHkpvobQ",
        "outputId": "60859bf4-c4f1-41aa-86cc-9678a04629b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of classes (num_classes): 64\n",
            "Sample encoded labels (train): [0 0 0 0 0]\n",
            "Corresponding class names: ['alarm_query' 'alarm_query' 'alarm_query' 'alarm_query' 'alarm_query']\n"
          ]
        }
      ],
      "source": [
        "# Tiền xử lý nhãn (Label Encoding)\n",
        "\n",
        "# 1. Gộp tất cả các nhãn từ cả 3 tập để đảm bảo LabelEncoder thấy tất cả các lớp\n",
        "all_intents = pd.concat([df_train['category'], df_val['category'], df_test['category']])\n",
        "\n",
        "# 2. Khởi tạo và fit LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_intents)\n",
        "\n",
        "# 3. Transform các nhãn\n",
        "y_train_encoded = label_encoder.transform(df_train['category'])\n",
        "y_val_encoded = label_encoder.transform(df_val['category'])\n",
        "y_test_encoded = label_encoder.transform(df_test['category'])\n",
        "\n",
        "# 4. Tách X (text)\n",
        "X_train = df_train['text']\n",
        "X_val = df_val['text']\n",
        "X_test = df_test['text']\n",
        "\n",
        "# 5. Lấy số lượng lớp và tên các lớp\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "print(f\"Total number of classes (num_classes): {num_classes}\")\n",
        "print(\"Sample encoded labels (train):\", y_train_encoded[:5])\n",
        "print(\"Corresponding class names:\", label_encoder.inverse_transform(y_train_encoded[:5]))"
      ],
      "id": "lyzYcHkpvobQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15znXEVvvobQ"
      },
      "source": [
        "## Nhiệm vụ 1: (Warm-up) Pipeline TF-IDF + Logistic Regression"
      ],
      "id": "15znXEVvvobQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyf1ULBgvobQ",
        "outputId": "8c6f2280-a13a-492f-e325-80a0d10afded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Task 1: TF-IDF + Logistic Regression ---\n",
            "Training TF-IDF + LR model...\n",
            "Evaluating on test set...\n",
            "\n",
            "Classification Report (Task 1):\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alarm_query       0.90      0.95      0.92        19\n",
            "            alarm_remove       1.00      0.73      0.84        11\n",
            "               alarm_set       0.77      0.89      0.83        19\n",
            "       audio_volume_down       1.00      0.75      0.86         8\n",
            "       audio_volume_mute       0.92      0.80      0.86        15\n",
            "         audio_volume_up       0.93      1.00      0.96        13\n",
            "          calendar_query       0.45      0.53      0.49        19\n",
            "         calendar_remove       0.89      0.89      0.89        19\n",
            "            calendar_set       0.87      0.68      0.76        19\n",
            "          cooking_recipe       0.59      0.68      0.63        19\n",
            "        datetime_convert       0.67      0.75      0.71         8\n",
            "          datetime_query       0.74      0.89      0.81        19\n",
            "        email_addcontact       0.78      0.88      0.82         8\n",
            "             email_query       0.83      0.79      0.81        19\n",
            "      email_querycontact       0.92      0.63      0.75        19\n",
            "         email_sendemail       0.81      0.89      0.85        19\n",
            "          general_affirm       1.00      1.00      1.00        19\n",
            "     general_commandstop       1.00      1.00      1.00        19\n",
            "         general_confirm       1.00      1.00      1.00        19\n",
            "        general_dontcare       0.90      1.00      0.95        19\n",
            "         general_explain       1.00      0.95      0.97        19\n",
            "            general_joke       1.00      1.00      1.00        12\n",
            "          general_negate       0.95      1.00      0.97        19\n",
            "          general_praise       0.95      1.00      0.97        19\n",
            "          general_quirky       0.36      0.26      0.30        19\n",
            "          general_repeat       0.90      1.00      0.95        19\n",
            "            iot_cleaning       1.00      1.00      1.00        16\n",
            "              iot_coffee       1.00      0.95      0.97        19\n",
            "     iot_hue_lightchange       0.75      0.79      0.77        19\n",
            "        iot_hue_lightdim       0.91      0.83      0.87        12\n",
            "        iot_hue_lightoff       0.89      0.89      0.89        19\n",
            "         iot_hue_lighton       0.67      0.67      0.67         3\n",
            "         iot_hue_lightup       1.00      0.86      0.92        14\n",
            "            iot_wemo_off       0.80      0.89      0.84         9\n",
            "             iot_wemo_on       0.78      1.00      0.88         7\n",
            "       lists_createoradd       0.68      0.79      0.73        19\n",
            "             lists_query       0.75      0.79      0.77        19\n",
            "            lists_remove       0.85      0.89      0.87        19\n",
            "          music_likeness       0.65      0.61      0.63        18\n",
            "             music_query       0.71      0.53      0.61        19\n",
            "          music_settings       1.00      0.57      0.73         7\n",
            "              news_query       0.75      0.63      0.69        19\n",
            "          play_audiobook       0.95      0.95      0.95        19\n",
            "               play_game       0.81      0.68      0.74        19\n",
            "              play_music       0.58      0.74      0.65        19\n",
            "           play_podcasts       1.00      0.84      0.91        19\n",
            "              play_radio       0.89      0.84      0.86        19\n",
            "             qa_currency       0.94      0.89      0.92        19\n",
            "           qa_definition       0.82      0.95      0.88        19\n",
            "              qa_factoid       0.48      0.58      0.52        19\n",
            "                qa_maths       0.92      0.86      0.89        14\n",
            "                qa_stock       1.00      0.95      0.97        19\n",
            "   recommendation_events       0.83      0.79      0.81        19\n",
            "recommendation_locations       0.81      0.89      0.85        19\n",
            "   recommendation_movies       1.00      1.00      1.00        10\n",
            "             social_post       0.95      1.00      0.97        19\n",
            "            social_query       0.80      0.89      0.84        18\n",
            "          takeaway_order       0.83      0.79      0.81        19\n",
            "          takeaway_query       0.89      0.89      0.89        19\n",
            "         transport_query       0.68      0.79      0.73        19\n",
            "          transport_taxi       1.00      1.00      1.00        18\n",
            "        transport_ticket       0.94      0.79      0.86        19\n",
            "       transport_traffic       1.00      0.95      0.97        19\n",
            "           weather_query       0.62      0.68      0.65        19\n",
            "\n",
            "                accuracy                           0.84      1076\n",
            "               macro avg       0.85      0.83      0.84      1076\n",
            "            weighted avg       0.84      0.84      0.84      1076\n",
            "\n",
            "\n",
            "F1-score (Macro) for Task 1: 0.8353\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Task 1: TF-IDF + Logistic Regression ---\")\n",
        "\n",
        "# 1. Tạo pipeline\n",
        "tfidf_lr_pipeline = make_pipeline(\n",
        "    TfidfVectorizer(max_features=5000), # Giới hạn 5000 features như trong tài liệu\n",
        "    LogisticRegression(max_iter=1000, random_state=42)\n",
        ")\n",
        "\n",
        "# 2. Huấn luyện pipeline\n",
        "print(\"Training TF-IDF + LR model...\")\n",
        "tfidf_lr_pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# 3. Đánh giá trên tập test\n",
        "print(\"Evaluating on test set...\")\n",
        "y_pred_task1 = tfidf_lr_pipeline.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report (Task 1):\")\n",
        "print(classification_report(y_test_encoded, y_pred_task1, target_names=class_names))\n",
        "\n",
        "# 4. Lưu kết quả để so sánh\n",
        "f1_macro_task1 = f1_score(y_test_encoded, y_pred_task1, average='macro')\n",
        "results = {}\n",
        "results['TF-IDF + LR'] = {'F1-score (Macro)': f1_macro_task1, 'Test Loss': 'N/A'}\n",
        "print(f\"\\nF1-score (Macro) for Task 1: {f1_macro_task1:.4f}\")"
      ],
      "id": "Eyf1ULBgvobQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Phương pháp\n",
        "\n",
        "* **Vector hóa:** TF-IDF với tối đa 5000 đặc trưng.\n",
        "* **Bộ phân loại:** Logistic Regression (max_iter = 1000).\n",
        "* **Đánh giá:** F1-macro trên tập test.\n",
        "\n",
        "#### Kết quả\n",
        "\n",
        "* **F1-macro:** ≈ 0.8353\n",
        "* **Độ chính xác trung bình:** ~84%\n",
        "* Một số intent như `general_affirm`, `general_negate`, `iot_cleaning` đạt F1 = 1.00, trong khi các intent mơ hồ hoặc phụ thuộc ngữ cảnh như `general_quirky` hoặc `qa_factoid` chỉ đạt khoảng 0.3–0.5.\n",
        "\n",
        "#### Nhận xét\n",
        "\n",
        "Mô hình truyền thống này vẫn thể hiện hiệu năng đáng kể, chứng tỏ **TF-IDF + Logistic Regression có thể nắm bắt tín hiệu thống kê mạnh mẽ từ văn bản ngắn**, đặc biệt khi các intent có ngữ vựng phân biệt rõ ràng.\n",
        "Tuy nhiên, **các hạn chế cố hữu** vẫn xuất hiện rõ:\n",
        "\n",
        "* **Mất trật tự từ (ordering loss)** → không hiểu quan hệ cú pháp.\n",
        "* **Thiếu biểu diễn ngữ nghĩa sâu** → không phân biệt được các ý định tương tự về từ vựng nhưng khác về mục đích.\n",
        "* Do đó, đây là **baseline mạnh nhưng chưa “ngữ nghĩa hóa”**, phù hợp để so sánh với các phương pháp embedding hiện đại hơn trong các nhiệm vụ tiếp theo."
      ],
      "metadata": {
        "id": "7NlCbksYTdSC"
      },
      "id": "7NlCbksYTdSC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh-Z5EsCvobR"
      },
      "source": [
        "## Nhiệm vụ 2: (Warm-up) Pipeline Word2Vec (Trung bình) + Dense Layer\n"
      ],
      "id": "Yh-Z5EsCvobR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XloCUS9PvobR",
        "outputId": "03639b26-4e2a-4419-d456-c40bd5c7eee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Task 2: Word2Vec (Average) + Dense Layer ---\n",
            "Preparing sentences for Word2Vec...\n",
            "Training Word2Vec on 8954 sentences...\n",
            "Word2Vec model trained. Vector size: 100\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Task 2: Word2Vec (Average) + Dense Layer ---\")\n",
        "\n",
        "# 1. Huấn luyện mô hình Word2Vec\n",
        "print(\"Preparing sentences for Word2Vec...\")\n",
        "# sentences = [text.split() for text in df_train['text']] # Giống X_train\n",
        "sentences = [text.split() for text in X_train]\n",
        "\n",
        "print(f\"Training Word2Vec on {len(sentences)} sentences...\")\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "embedding_dim_w2v = w2v_model.vector_size\n",
        "print(f\"Word2Vec model trained. Vector size: {embedding_dim_w2v}\")"
      ],
      "id": "XloCUS9PvobR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbYyWSewvobR",
        "outputId": "0e902cb3-b6a3-4f65-8948-d95a823bfde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test avg vector shape: (100,)\n"
          ]
        }
      ],
      "source": [
        "# 2. Viết hàm để chuyển mỗi câu thành vector trung bình\n",
        "def sentence_to_avg_vector(text, model, embedding_dim):\n",
        "    words = text.split()\n",
        "    # Lấy vector cho mỗi từ có trong vocab của Word2Vec\n",
        "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "\n",
        "    if not word_vectors:\n",
        "        # Nếu không có từ nào trong vocab, trả về vector 0\n",
        "        return np.zeros(embedding_dim)\n",
        "\n",
        "    # Tính trung bình cộng\n",
        "    avg_vector = np.mean(word_vectors, axis=0)\n",
        "    return avg_vector\n",
        "\n",
        "# Test hàm\n",
        "test_vec = sentence_to_avg_vector(\"this is a test\", w2v_model, embedding_dim_w2v)\n",
        "print(f\"Test avg vector shape: {test_vec.shape}\")"
      ],
      "id": "dbYyWSewvobR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylxPfOrYvobR",
        "outputId": "cb4c2167-9365-4382-d840-b138fc920811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating average vectors for train, val, and test sets...\n",
            "X_train_avg shape: (8954, 100)\n",
            "X_val_avg shape: (1076, 100)\n",
            "X_test_avg shape: (1076, 100)\n"
          ]
        }
      ],
      "source": [
        "# 3. Tạo dữ liệu train/val/test X_..._avg\n",
        "print(\"Creating average vectors for train, val, and test sets...\")\n",
        "X_train_avg = np.array([sentence_to_avg_vector(text, w2v_model, embedding_dim_w2v) for text in X_train])\n",
        "X_val_avg = np.array([sentence_to_avg_vector(text, w2v_model, embedding_dim_w2v) for text in X_val])\n",
        "X_test_avg = np.array([sentence_to_avg_vector(text, w2v_model, embedding_dim_w2v) for text in X_test])\n",
        "\n",
        "print(\"X_train_avg shape:\", X_train_avg.shape)\n",
        "print(\"X_val_avg shape:\", X_val_avg.shape)\n",
        "print(\"X_test_avg shape:\", X_test_avg.shape)"
      ],
      "id": "ylxPfOrYvobR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AS5LdIpSvobS",
        "outputId": "a6a91129-8d9c-4d9b-9385-1ba841c9aaff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m12,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,184\u001b[0m (82.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,184</span> (82.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,184\u001b[0m (82.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,184</span> (82.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training W2V (Avg) + Dense model...\n",
            "Epoch 1/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0182 - loss: 4.1653 - val_accuracy: 0.0288 - val_loss: 4.1176\n",
            "Epoch 2/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0300 - loss: 4.1201 - val_accuracy: 0.0511 - val_loss: 4.0845\n",
            "Epoch 3/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0389 - loss: 4.0859 - val_accuracy: 0.0604 - val_loss: 4.0275\n",
            "Epoch 4/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0482 - loss: 4.0252 - val_accuracy: 0.0874 - val_loss: 3.9416\n",
            "Epoch 5/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0579 - loss: 3.9400 - val_accuracy: 0.0846 - val_loss: 3.8459\n",
            "Epoch 6/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0727 - loss: 3.8478 - val_accuracy: 0.1152 - val_loss: 3.7499\n",
            "Epoch 7/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0808 - loss: 3.7627 - val_accuracy: 0.1032 - val_loss: 3.6706\n",
            "Epoch 8/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0871 - loss: 3.6999 - val_accuracy: 0.1357 - val_loss: 3.5964\n",
            "Epoch 9/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0958 - loss: 3.6298 - val_accuracy: 0.1329 - val_loss: 3.5340\n",
            "Epoch 10/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1142 - loss: 3.5757 - val_accuracy: 0.1506 - val_loss: 3.4836\n",
            "Epoch 11/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1199 - loss: 3.5147 - val_accuracy: 0.1645 - val_loss: 3.4444\n",
            "Epoch 12/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1157 - loss: 3.5009 - val_accuracy: 0.1654 - val_loss: 3.4040\n",
            "Epoch 13/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1238 - loss: 3.4625 - val_accuracy: 0.1710 - val_loss: 3.3697\n",
            "Epoch 14/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1339 - loss: 3.4363 - val_accuracy: 0.1747 - val_loss: 3.3457\n",
            "Epoch 15/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1311 - loss: 3.4197 - val_accuracy: 0.1757 - val_loss: 3.3189\n",
            "Epoch 16/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1326 - loss: 3.3970 - val_accuracy: 0.1812 - val_loss: 3.2883\n",
            "Epoch 17/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1389 - loss: 3.3611 - val_accuracy: 0.1803 - val_loss: 3.2721\n",
            "Epoch 18/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1474 - loss: 3.3472 - val_accuracy: 0.1803 - val_loss: 3.2461\n",
            "Epoch 19/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1517 - loss: 3.3050 - val_accuracy: 0.1905 - val_loss: 3.2212\n",
            "Epoch 20/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1479 - loss: 3.3124 - val_accuracy: 0.1952 - val_loss: 3.2022\n",
            "\n",
            "Evaluating model (Task 2):\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2272 - loss: 3.1158\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Classification Report (Task 2):\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alarm_query       0.05      0.11      0.07        19\n",
            "            alarm_remove       0.00      0.00      0.00        11\n",
            "               alarm_set       0.33      0.84      0.47        19\n",
            "       audio_volume_down       0.00      0.00      0.00         8\n",
            "       audio_volume_mute       0.00      0.00      0.00        15\n",
            "         audio_volume_up       0.00      0.00      0.00        13\n",
            "          calendar_query       0.00      0.00      0.00        19\n",
            "         calendar_remove       0.24      0.26      0.25        19\n",
            "            calendar_set       0.14      0.11      0.12        19\n",
            "          cooking_recipe       0.00      0.00      0.00        19\n",
            "        datetime_convert       0.00      0.00      0.00         8\n",
            "          datetime_query       0.12      0.68      0.20        19\n",
            "        email_addcontact       0.00      0.00      0.00         8\n",
            "             email_query       0.18      0.11      0.13        19\n",
            "      email_querycontact       0.17      0.05      0.08        19\n",
            "         email_sendemail       0.25      0.32      0.28        19\n",
            "          general_affirm       0.20      0.42      0.27        19\n",
            "     general_commandstop       0.58      0.74      0.65        19\n",
            "         general_confirm       0.56      0.79      0.65        19\n",
            "        general_dontcare       0.16      0.47      0.23        19\n",
            "         general_explain       0.07      0.11      0.09        19\n",
            "            general_joke       0.00      0.00      0.00        12\n",
            "          general_negate       0.33      0.26      0.29        19\n",
            "          general_praise       0.34      0.58      0.43        19\n",
            "          general_quirky       0.00      0.00      0.00        19\n",
            "          general_repeat       0.38      0.32      0.34        19\n",
            "            iot_cleaning       0.33      0.50      0.40        16\n",
            "              iot_coffee       0.11      0.26      0.16        19\n",
            "     iot_hue_lightchange       0.48      0.63      0.55        19\n",
            "        iot_hue_lightdim       0.00      0.00      0.00        12\n",
            "        iot_hue_lightoff       0.30      0.89      0.45        19\n",
            "         iot_hue_lighton       0.00      0.00      0.00         3\n",
            "         iot_hue_lightup       0.00      0.00      0.00        14\n",
            "            iot_wemo_off       1.00      0.11      0.20         9\n",
            "             iot_wemo_on       0.00      0.00      0.00         7\n",
            "       lists_createoradd       0.31      0.21      0.25        19\n",
            "             lists_query       0.06      0.11      0.08        19\n",
            "            lists_remove       0.27      0.16      0.20        19\n",
            "          music_likeness       0.00      0.00      0.00        18\n",
            "             music_query       0.05      0.05      0.05        19\n",
            "          music_settings       0.00      0.00      0.00         7\n",
            "              news_query       0.08      0.05      0.06        19\n",
            "          play_audiobook       0.08      0.05      0.06        19\n",
            "               play_game       0.00      0.00      0.00        19\n",
            "              play_music       0.00      0.00      0.00        19\n",
            "           play_podcasts       0.15      0.11      0.12        19\n",
            "              play_radio       0.00      0.00      0.00        19\n",
            "             qa_currency       0.06      0.05      0.06        19\n",
            "           qa_definition       0.00      0.00      0.00        19\n",
            "              qa_factoid       0.10      0.26      0.14        19\n",
            "                qa_maths       0.00      0.00      0.00        14\n",
            "                qa_stock       0.00      0.00      0.00        19\n",
            "   recommendation_events       0.23      0.16      0.19        19\n",
            "recommendation_locations       0.00      0.00      0.00        19\n",
            "   recommendation_movies       0.00      0.00      0.00        10\n",
            "             social_post       0.33      0.11      0.16        19\n",
            "            social_query       0.00      0.00      0.00        18\n",
            "          takeaway_order       0.11      0.16      0.13        19\n",
            "          takeaway_query       0.00      0.00      0.00        19\n",
            "         transport_query       0.12      0.16      0.14        19\n",
            "          transport_taxi       0.00      0.00      0.00        18\n",
            "        transport_ticket       0.17      0.68      0.27        19\n",
            "       transport_traffic       0.25      0.05      0.09        19\n",
            "           weather_query       0.00      0.00      0.00        19\n",
            "\n",
            "                accuracy                           0.19      1076\n",
            "               macro avg       0.14      0.17      0.13      1076\n",
            "            weighted avg       0.14      0.19      0.14      1076\n",
            "\n",
            "\n",
            "F1-score (Macro) for Task 2: 0.1301\n",
            "Test Loss for Task 2: 3.2135\n"
          ]
        }
      ],
      "source": [
        "# 4. Xây dựng mô hình Sequential của Keras\n",
        "w2v_avg_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(embedding_dim_w2v,)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "w2v_avg_model.summary()\n",
        "\n",
        "# 5. Compile, huấn luyện và đánh giá mô hình\n",
        "w2v_avg_model.compile(\n",
        "    loss='sparse_categorical_crossentropy', # Dùng vì y_encoded là số nguyên\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Dùng EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "print(\"\\nTraining W2V (Avg) + Dense model...\")\n",
        "history_task2 = w2v_avg_model.fit(\n",
        "    X_train_avg, y_train_encoded,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_avg, y_val_encoded),\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 6. Đánh giá\n",
        "print(\"\\nEvaluating model (Task 2):\")\n",
        "test_loss_task2, test_acc_task2 = w2v_avg_model.evaluate(X_test_avg, y_test_encoded)\n",
        "\n",
        "y_pred_prob_task2 = w2v_avg_model.predict(X_test_avg)\n",
        "y_pred_task2 = np.argmax(y_pred_prob_task2, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report (Task 2):\")\n",
        "print(classification_report(y_test_encoded, y_pred_task2, target_names=class_names))\n",
        "\n",
        "# 7. Lưu kết quả\n",
        "f1_macro_task2 = f1_score(y_test_encoded, y_pred_task2, average='macro')\n",
        "results['W2V (Avg) + Dense'] = {'F1-score (Macro)': f1_macro_task2, 'Test Loss': test_loss_task2}\n",
        "print(f\"\\nF1-score (Macro) for Task 2: {f1_macro_task2:.4f}\")\n",
        "print(f\"Test Loss for Task 2: {test_loss_task2:.4f}\")"
      ],
      "id": "AS5LdIpSvobS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Phương pháp\n",
        "\n",
        "* **Embedding:** Word2Vec huấn luyện trên toàn bộ tập huấn luyện (100 chiều).\n",
        "* **Biểu diễn câu:** Trung bình cộng các vector từ (average pooling).\n",
        "* **Kiến trúc:** 2 tầng Dense (128 → 64) với Dropout = 0.5 để tránh overfitting.\n",
        "* **Huấn luyện:** 20 epoch, EarlyStopping theo `val_loss`.\n",
        "\n",
        "#### Kết quả\n",
        "\n",
        "* **F1-macro:** ≈ 0.13\n",
        "* **Độ chính xác:** ~19%\n",
        "* **Test loss:** ≈ 3.21\n",
        "\n",
        "Một số lớp có kết quả rất thấp (đa phần F1 ≈ 0.0), chỉ vài lớp phổ biến có thể đạt mức 0.4–0.6 nhờ trùng lặp ngữ vựng.\n",
        "\n",
        "#### Nhận xét\n",
        "\n",
        "Hiệu năng của mô hình **giảm mạnh so với baseline TF-IDF**, nguyên nhân có thể đến từ:\n",
        "\n",
        "* **Biểu diễn trung bình Word2Vec** làm **mất thông tin thứ tự và cấu trúc ngữ cảnh**, tương tự TF-IDF nhưng phức tạp hơn.\n",
        "* **Mạng Dense nông** không đủ năng lực biểu diễn mối quan hệ phi tuyến phức tạp giữa các intent.\n",
        "* **Dropout cao (0.5)** và kích thước embedding nhỏ (100 chiều) khiến mô hình **khó hội tụ**.\n",
        "* **Dữ liệu huấn luyện hạn chế** → Word2Vec học embedding chưa ổn định, làm lan truyền sai lệch vào tầng Dense.\n",
        "\n",
        "=> Mô hình này cho thấy **việc chuyển từ đặc trưng thống kê sang embedding học được chưa đảm bảo cải thiện hiệu năng**, trừ khi có biểu diễn ngữ cảnh sâu hơn (như BiLSTM hoặc Transformer trong các nhiệm vụ sau)."
      ],
      "metadata": {
        "id": "BfIXhqzgU56u"
      },
      "id": "BfIXhqzgU56u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drk7N7dgvobS"
      },
      "source": [
        "## Bước 3a: Tiền xử lý cho Mô hình Chuỗi (Tokenizer & Padding)\n",
        "\n",
        "Đây là bước tiền xử lý chung, dùng cho cả Nhiệm vụ 3 và 4."
      ],
      "id": "Drk7N7dgvobS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHe_8G70vobS",
        "outputId": "dae382ce-4386-47bc-9f38-8b828e1fbac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual vocabulary size (từ Tokenizer): 4265\n",
            "Using vocab_size = 4265 cho Embedding layer\n",
            "\n",
            "Padding results:\n",
            "X_train_pad shape: (8954, 50)\n",
            "X_val_pad shape: (1076, 50)\n",
            "X_test_pad shape: (1076, 50)\n",
            "\n",
            "Example original sequence (train):\n",
            "[9, 99, 24, 5, 26, 35, 92, 62]\n",
            "\n",
            "Example padded sequence (train):\n",
            "[ 9 99 24  5 26 35 92 62  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n"
          ]
        }
      ],
      "source": [
        "# 1. Tiền xử lý cho mô hình chuỗi (Tokenizer & Padding)\n",
        "vocab_size_keras = 10000 # Kích thước từ vựng (có thể chọn 5000)\n",
        "max_len = 50 # Độ dài chuỗi tối đa (theo gợi ý tài liệu)\n",
        "oov_token = \"<UNK>\" # Token cho các từ ngoài từ vựng\n",
        "\n",
        "# a. Tokenizer: Tạo vocab và chuyển text thành chuỗi chỉ số\n",
        "tokenizer = Tokenizer(num_words=vocab_size_keras, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1 # +1 cho padding (index 0)\n",
        "print(f\"Actual vocabulary size (từ Tokenizer): {vocab_size}\")\n",
        "\n",
        "# Giới hạn vocab_size về đúng giá trị num_words (nếu nó lớn hơn)\n",
        "if vocab_size > vocab_size_keras:\n",
        "    vocab_size = vocab_size_keras\n",
        "print(f\"Using vocab_size = {vocab_size} cho Embedding layer\")\n",
        "\n",
        "# Chuyển text thành chuỗi\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "val_sequences = tokenizer.texts_to_sequences(X_val)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# b. Padding: Đảm bảo các chuỗi có cùng độ dài\n",
        "X_train_pad = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "X_val_pad = pad_sequences(val_sequences, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "print(\"\\nPadding results:\")\n",
        "print(\"X_train_pad shape:\", X_train_pad.shape)\n",
        "print(\"X_val_pad shape:\", X_val_pad.shape)\n",
        "print(\"X_test_pad shape:\", X_test_pad.shape)\n",
        "print(\"\\nExample original sequence (train):\")\n",
        "print(train_sequences[0])\n",
        "print(\"\\nExample padded sequence (train):\")\n",
        "print(X_train_pad[0])"
      ],
      "id": "IHe_8G70vobS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG0K_BHTvobS"
      },
      "source": [
        "## Nhiệm vụ 3: Mô hình Nâng cao (Embedding Pre-trained + LSTM)"
      ],
      "id": "hG0K_BHTvobS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H372XgjyvobS",
        "outputId": "dc08b709-85ca-4bc5-fe29-1b265c590040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Task 3: Pre-trained Embedding + LSTM ---\n",
            "Building embedding matrix with shape (4265, 100)...\n",
            "Embedding matrix shape: (4265, 100)\n",
            "Number of words found in Word2Vec vocab: 4196 / 4265\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Task 3: Pre-trained Embedding + LSTM ---\")\n",
        "\n",
        "# 2. Tạo ma trận trọng số cho Embedding Layer từ Word2Vec\n",
        "embedding_dim = w2v_model.vector_size # Phải khớp với W2V ở Task 2 (100)\n",
        "\n",
        "print(f\"Building embedding matrix with shape ({vocab_size}, {embedding_dim})...\")\n",
        "# Khởi tạo ma trận zero\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "hits = 0\n",
        "# Điền vào ma trận\n",
        "for word, i in word_index.items():\n",
        "    if i < vocab_size: # Chỉ xét các từ trong vocab_size đã định\n",
        "        if word in w2v_model.wv:\n",
        "            embedding_matrix[i] = w2v_model.wv[word]\n",
        "            hits += 1\n",
        "    # Những từ không có trong w2v_model (hoặc ngoài vocab_size) sẽ là vector 0\n",
        "\n",
        "print(\"Embedding matrix shape:\", embedding_matrix.shape)\n",
        "print(f\"Number of words found in Word2Vec vocab: {hits} / {vocab_size}\")"
      ],
      "id": "H372XgjyvobS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6-JREbqbvobT",
        "outputId": "d479c866-d668-49dd-d80e-9055b73b7b4d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │       \u001b[38;5;34m426,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">426,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m426,500\u001b[0m (1.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,500</span> (1.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m426,500\u001b[0m (1.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,500</span> (1.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM (Pre-trained) model...\n",
            "Epoch 1/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - accuracy: 0.0145 - loss: 4.1475 - val_accuracy: 0.0260 - val_loss: 4.0983\n",
            "Epoch 2/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 105ms/step - accuracy: 0.0267 - loss: 4.0806 - val_accuracy: 0.0465 - val_loss: 3.9630\n",
            "Epoch 3/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 105ms/step - accuracy: 0.0378 - loss: 3.9741 - val_accuracy: 0.0539 - val_loss: 3.8345\n",
            "Epoch 4/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 108ms/step - accuracy: 0.0500 - loss: 3.9168 - val_accuracy: 0.0623 - val_loss: 3.8363\n",
            "Epoch 5/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 104ms/step - accuracy: 0.0528 - loss: 3.8456 - val_accuracy: 0.0604 - val_loss: 3.7731\n",
            "Epoch 6/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 103ms/step - accuracy: 0.0557 - loss: 3.8437 - val_accuracy: 0.0762 - val_loss: 3.7546\n",
            "Epoch 7/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 106ms/step - accuracy: 0.0604 - loss: 3.8213 - val_accuracy: 0.0688 - val_loss: 3.7061\n",
            "Epoch 8/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 104ms/step - accuracy: 0.0613 - loss: 3.7839 - val_accuracy: 0.0660 - val_loss: 3.7449\n",
            "Epoch 9/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 104ms/step - accuracy: 0.0572 - loss: 3.7334 - val_accuracy: 0.0734 - val_loss: 3.7230\n",
            "Epoch 10/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 107ms/step - accuracy: 0.0667 - loss: 3.7069 - val_accuracy: 0.0809 - val_loss: 3.6042\n",
            "Epoch 11/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 108ms/step - accuracy: 0.0697 - loss: 3.6433 - val_accuracy: 0.0827 - val_loss: 3.6149\n",
            "Epoch 12/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 104ms/step - accuracy: 0.0713 - loss: 3.6440 - val_accuracy: 0.0929 - val_loss: 3.5631\n",
            "Epoch 13/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 103ms/step - accuracy: 0.0740 - loss: 3.6248 - val_accuracy: 0.0790 - val_loss: 3.5385\n",
            "Epoch 14/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 108ms/step - accuracy: 0.0775 - loss: 3.5975 - val_accuracy: 0.0901 - val_loss: 3.5765\n",
            "Epoch 15/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 103ms/step - accuracy: 0.0820 - loss: 3.5858 - val_accuracy: 0.0883 - val_loss: 3.5216\n",
            "Epoch 16/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 103ms/step - accuracy: 0.0849 - loss: 3.5601 - val_accuracy: 0.0799 - val_loss: 3.5797\n",
            "Epoch 17/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 108ms/step - accuracy: 0.0799 - loss: 3.5769 - val_accuracy: 0.0836 - val_loss: 3.5408\n",
            "Epoch 18/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 103ms/step - accuracy: 0.0970 - loss: 3.5191 - val_accuracy: 0.0967 - val_loss: 3.4773\n",
            "Epoch 19/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 103ms/step - accuracy: 0.0871 - loss: 3.5432 - val_accuracy: 0.1069 - val_loss: 3.4314\n",
            "Epoch 20/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 106ms/step - accuracy: 0.0885 - loss: 3.5525 - val_accuracy: 0.0901 - val_loss: 3.4508\n",
            "\n",
            "Evaluating model (Task 3):\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1104 - loss: 3.4626\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
            "\n",
            "Classification Report (Task 3):\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alarm_query       0.00      0.00      0.00        19\n",
            "            alarm_remove       0.00      0.00      0.00        11\n",
            "               alarm_set       0.71      0.53      0.61        19\n",
            "       audio_volume_down       0.00      0.00      0.00         8\n",
            "       audio_volume_mute       0.00      0.00      0.00        15\n",
            "         audio_volume_up       0.00      0.00      0.00        13\n",
            "          calendar_query       0.00      0.00      0.00        19\n",
            "         calendar_remove       0.00      0.00      0.00        19\n",
            "            calendar_set       0.00      0.00      0.00        19\n",
            "          cooking_recipe       0.00      0.00      0.00        19\n",
            "        datetime_convert       0.00      0.00      0.00         8\n",
            "          datetime_query       0.02      0.05      0.03        19\n",
            "        email_addcontact       0.00      0.00      0.00         8\n",
            "             email_query       0.00      0.00      0.00        19\n",
            "      email_querycontact       0.00      0.00      0.00        19\n",
            "         email_sendemail       0.00      0.00      0.00        19\n",
            "          general_affirm       0.09      0.84      0.16        19\n",
            "     general_commandstop       0.33      0.26      0.29        19\n",
            "         general_confirm       0.27      0.89      0.41        19\n",
            "        general_dontcare       0.00      0.00      0.00        19\n",
            "         general_explain       0.00      0.00      0.00        19\n",
            "            general_joke       0.00      0.00      0.00        12\n",
            "          general_negate       0.00      0.00      0.00        19\n",
            "          general_praise       0.00      0.00      0.00        19\n",
            "          general_quirky       0.00      0.00      0.00        19\n",
            "          general_repeat       0.16      0.21      0.18        19\n",
            "            iot_cleaning       0.00      0.00      0.00        16\n",
            "              iot_coffee       0.00      0.00      0.00        19\n",
            "     iot_hue_lightchange       0.25      0.74      0.37        19\n",
            "        iot_hue_lightdim       0.00      0.00      0.00        12\n",
            "        iot_hue_lightoff       0.43      0.84      0.57        19\n",
            "         iot_hue_lighton       0.00      0.00      0.00         3\n",
            "         iot_hue_lightup       0.00      0.00      0.00        14\n",
            "            iot_wemo_off       0.00      0.00      0.00         9\n",
            "             iot_wemo_on       0.00      0.00      0.00         7\n",
            "       lists_createoradd       0.00      0.00      0.00        19\n",
            "             lists_query       0.00      0.00      0.00        19\n",
            "            lists_remove       0.00      0.00      0.00        19\n",
            "          music_likeness       0.00      0.00      0.00        18\n",
            "             music_query       0.00      0.00      0.00        19\n",
            "          music_settings       0.00      0.00      0.00         7\n",
            "              news_query       0.00      0.00      0.00        19\n",
            "          play_audiobook       0.00      0.00      0.00        19\n",
            "               play_game       0.00      0.00      0.00        19\n",
            "              play_music       0.00      0.00      0.00        19\n",
            "           play_podcasts       0.00      0.00      0.00        19\n",
            "              play_radio       0.00      0.00      0.00        19\n",
            "             qa_currency       0.05      0.11      0.06        19\n",
            "           qa_definition       0.00      0.00      0.00        19\n",
            "              qa_factoid       0.04      0.53      0.07        19\n",
            "                qa_maths       0.00      0.00      0.00        14\n",
            "                qa_stock       0.04      0.37      0.07        19\n",
            "   recommendation_events       0.00      0.00      0.00        19\n",
            "recommendation_locations       0.00      0.00      0.00        19\n",
            "   recommendation_movies       0.00      0.00      0.00        10\n",
            "             social_post       0.00      0.00      0.00        19\n",
            "            social_query       0.00      0.00      0.00        18\n",
            "          takeaway_order       0.00      0.00      0.00        19\n",
            "          takeaway_query       0.00      0.00      0.00        19\n",
            "         transport_query       0.00      0.00      0.00        19\n",
            "          transport_taxi       0.07      0.28      0.11        18\n",
            "        transport_ticket       0.26      0.58      0.35        19\n",
            "       transport_traffic       0.00      0.00      0.00        19\n",
            "           weather_query       0.00      0.00      0.00        19\n",
            "\n",
            "                accuracy                           0.11      1076\n",
            "               macro avg       0.04      0.10      0.05      1076\n",
            "            weighted avg       0.05      0.11      0.06      1076\n",
            "\n",
            "\n",
            "F1-score (Macro) for Task 3: 0.0513\n",
            "Test Loss for Task 3: 3.4492\n"
          ]
        }
      ],
      "source": [
        "# 3. Xây dựng mô hình Sequential với LSTM\n",
        "lstm_model_pretrained = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,       # Kích thước từ vựng\n",
        "        output_dim=embedding_dim,   # Kích thước vector (100)\n",
        "        weights=[embedding_matrix], # Khởi tạo trọng số\n",
        "        input_length=max_len,       # Độ dài chuỗi (50)\n",
        "        trainable=False           # Đóng băng lớp Embedding\n",
        "    ),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "lstm_model_pretrained.summary()\n",
        "\n",
        "# 4. Compile, huấn luyện\n",
        "lstm_model_pretrained.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nTraining LSTM (Pre-trained) model...\")\n",
        "history_task3 = lstm_model_pretrained.fit(\n",
        "    X_train_pad, y_train_encoded,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_pad, y_val_encoded),\n",
        "    callbacks=[early_stopping], # Dùng lại early_stopping từ Task 2\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5. Đánh giá\n",
        "print(\"\\nEvaluating model (Task 3):\")\n",
        "test_loss_task3, test_acc_task3 = lstm_model_pretrained.evaluate(X_test_pad, y_test_encoded)\n",
        "\n",
        "y_pred_prob_task3 = lstm_model_pretrained.predict(X_test_pad)\n",
        "y_pred_task3 = np.argmax(y_pred_prob_task3, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report (Task 3):\")\n",
        "print(classification_report(y_test_encoded, y_pred_task3, target_names=class_names))\n",
        "\n",
        "# 6. Lưu kết quả\n",
        "f1_macro_task3 = f1_score(y_test_encoded, y_pred_task3, average='macro')\n",
        "results['LSTM (Pre-trained)'] = {'F1-score (Macro)': f1_macro_task3, 'Test Loss': test_loss_task3}\n",
        "print(f\"\\nF1-score (Macro) for Task 3: {f1_macro_task3:.4f}\")\n",
        "print(f\"Test Loss for Task 3: {test_loss_task3:.4f}\")"
      ],
      "id": "6-JREbqbvobT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Phương pháp\n",
        "\n",
        "* **Embedding:** Sử dụng trọng số từ Word2Vec huấn luyện trước (100 chiều).\n",
        "* **Embedding layer:** Được **đóng băng** để mô hình tập trung học phần tuần tự.\n",
        "* **Kiến trúc:** `Embedding (frozen)` → `LSTM(128, dropout=0.2, recurrent_dropout=0.2)` → `Dense(softmax)`.\n",
        "* **Tham số:** `max_len = 50`, `vocab_size = 4265`.\n",
        "* **Huấn luyện:** 20 epoch với EarlyStopping.\n",
        "\n",
        "#### Kết quả\n",
        "\n",
        "* **F1-macro:** 0.0513\n",
        "* **Độ chính xác:** 11.04%\n",
        "* **Test Loss:** 3.4492\n",
        "* Mặc dù một vài intent có dấu hiệu học được như `alarm_set`, `iot_hue_lightoff`, `general_confirm`, phần lớn các intent còn lại cho F1 ≈ 0.0.\n",
        "\n",
        "#### Phân tích\n",
        "\n",
        "Hiệu năng cực thấp cho thấy **mô hình chưa khai thác được lợi thế của LSTM**, nguyên nhân chính bao gồm:\n",
        "\n",
        "1. **Embedding đóng băng** → mô hình không thể điều chỉnh biểu diễn để phù hợp với nhiệm vụ phân loại intent cụ thể.\n",
        "2. **Word2Vec huấn luyện hạn chế** → nhiều từ không có vector ngữ cảnh mạnh, khiến đầu vào LSTM nghèo thông tin.\n",
        "3. **LSTM đơn tầng** với dropout cao khiến mô hình **khó hội tụ**, đặc biệt khi dữ liệu gồm 64 lớp với tần suất không cân bằng.\n",
        "4. **Thiếu fine-tuning embedding hoặc attention** → mô hình chưa học được trọng tâm ngữ nghĩa trong câu.\n",
        "\n",
        "#### Nhận xét\n",
        "\n",
        "LSTM có khả năng học tuần tự, nhưng trong thiết lập hiện tại, **hiệu năng giảm mạnh so với TF-IDF (0.83 F1)**.\n",
        "Điều này nhấn mạnh rằng **embedding tiền huấn luyện cần được tinh chỉnh (fine-tune)** hoặc kết hợp với **kiến trúc ngữ cảnh sâu hơn** (BiLSTM, GRU, hoặc Transformer) để phát huy hiệu quả thật sự.\n",
        "\n",
        "→ Đây là **bước bản lề**: cho thấy sự chuyển dịch từ biểu diễn thống kê sang biểu diễn ngữ cảnh **không đơn giản** và đòi hỏi chiến lược tinh chỉnh phù hợp."
      ],
      "metadata": {
        "id": "Jlf2c10OVs4U"
      },
      "id": "Jlf2c10OVs4U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB96ys7nvobT"
      },
      "source": [
        "## Nhiệm vụ 4: Mô hình Nâng cao (Embedding học từ đầu + LSTM)"
      ],
      "id": "fB96ys7nvobT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lwdc0CDDvobT",
        "outputId": "a74b4a9a-496d-4c39-e7d7-f1a3be736a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Task 4: Embedding from Scratch + LSTM ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM (Scratch) model...\n",
            "Epoch 1/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 121ms/step - accuracy: 0.0172 - loss: 4.1505 - val_accuracy: 0.0177 - val_loss: 4.1267\n",
            "Epoch 2/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 116ms/step - accuracy: 0.0198 - loss: 4.1380 - val_accuracy: 0.0177 - val_loss: 4.1260\n",
            "Epoch 3/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 120ms/step - accuracy: 0.0126 - loss: 4.1367 - val_accuracy: 0.0177 - val_loss: 4.1274\n",
            "Epoch 4/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 120ms/step - accuracy: 0.0187 - loss: 4.1346 - val_accuracy: 0.0177 - val_loss: 4.1246\n",
            "Epoch 5/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 116ms/step - accuracy: 0.0152 - loss: 4.1299 - val_accuracy: 0.0177 - val_loss: 4.1254\n",
            "Epoch 6/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 120ms/step - accuracy: 0.0141 - loss: 4.1303 - val_accuracy: 0.0177 - val_loss: 4.1254\n",
            "Epoch 7/20\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 120ms/step - accuracy: 0.0151 - loss: 4.1303 - val_accuracy: 0.0177 - val_loss: 4.1256\n",
            "\n",
            "Evaluating model (Task 4):\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0216 - loss: 4.1527\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "\n",
            "Classification Report (Task 4):\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alarm_query       0.00      0.00      0.00        19\n",
            "            alarm_remove       0.00      0.00      0.00        11\n",
            "               alarm_set       0.00      0.00      0.00        19\n",
            "       audio_volume_down       0.00      0.00      0.00         8\n",
            "       audio_volume_mute       0.00      0.00      0.00        15\n",
            "         audio_volume_up       0.00      0.00      0.00        13\n",
            "          calendar_query       0.00      0.00      0.00        19\n",
            "         calendar_remove       0.00      0.00      0.00        19\n",
            "            calendar_set       0.00      0.00      0.00        19\n",
            "          cooking_recipe       0.00      0.00      0.00        19\n",
            "        datetime_convert       0.00      0.00      0.00         8\n",
            "          datetime_query       0.00      0.00      0.00        19\n",
            "        email_addcontact       0.00      0.00      0.00         8\n",
            "             email_query       0.00      0.00      0.00        19\n",
            "      email_querycontact       0.00      0.00      0.00        19\n",
            "         email_sendemail       0.00      0.00      0.00        19\n",
            "          general_affirm       0.00      0.00      0.00        19\n",
            "     general_commandstop       0.00      0.00      0.00        19\n",
            "         general_confirm       0.00      0.00      0.00        19\n",
            "        general_dontcare       0.02      1.00      0.03        19\n",
            "         general_explain       0.00      0.00      0.00        19\n",
            "            general_joke       0.00      0.00      0.00        12\n",
            "          general_negate       0.00      0.00      0.00        19\n",
            "          general_praise       0.00      0.00      0.00        19\n",
            "          general_quirky       0.00      0.00      0.00        19\n",
            "          general_repeat       0.00      0.00      0.00        19\n",
            "            iot_cleaning       0.00      0.00      0.00        16\n",
            "              iot_coffee       0.00      0.00      0.00        19\n",
            "     iot_hue_lightchange       0.00      0.00      0.00        19\n",
            "        iot_hue_lightdim       0.00      0.00      0.00        12\n",
            "        iot_hue_lightoff       0.00      0.00      0.00        19\n",
            "         iot_hue_lighton       0.00      0.00      0.00         3\n",
            "         iot_hue_lightup       0.00      0.00      0.00        14\n",
            "            iot_wemo_off       0.00      0.00      0.00         9\n",
            "             iot_wemo_on       0.00      0.00      0.00         7\n",
            "       lists_createoradd       0.00      0.00      0.00        19\n",
            "             lists_query       0.00      0.00      0.00        19\n",
            "            lists_remove       0.00      0.00      0.00        19\n",
            "          music_likeness       0.00      0.00      0.00        18\n",
            "             music_query       0.00      0.00      0.00        19\n",
            "          music_settings       0.00      0.00      0.00         7\n",
            "              news_query       0.00      0.00      0.00        19\n",
            "          play_audiobook       0.00      0.00      0.00        19\n",
            "               play_game       0.00      0.00      0.00        19\n",
            "              play_music       0.00      0.00      0.00        19\n",
            "           play_podcasts       0.00      0.00      0.00        19\n",
            "              play_radio       0.00      0.00      0.00        19\n",
            "             qa_currency       0.00      0.00      0.00        19\n",
            "           qa_definition       0.00      0.00      0.00        19\n",
            "              qa_factoid       0.00      0.00      0.00        19\n",
            "                qa_maths       0.00      0.00      0.00        14\n",
            "                qa_stock       0.00      0.00      0.00        19\n",
            "   recommendation_events       0.00      0.00      0.00        19\n",
            "recommendation_locations       0.00      0.00      0.00        19\n",
            "   recommendation_movies       0.00      0.00      0.00        10\n",
            "             social_post       0.00      0.00      0.00        19\n",
            "            social_query       0.00      0.00      0.00        18\n",
            "          takeaway_order       0.00      0.00      0.00        19\n",
            "          takeaway_query       0.00      0.00      0.00        19\n",
            "         transport_query       0.00      0.00      0.00        19\n",
            "          transport_taxi       0.00      0.00      0.00        18\n",
            "        transport_ticket       0.00      0.00      0.00        19\n",
            "       transport_traffic       0.00      0.00      0.00        19\n",
            "           weather_query       0.00      0.00      0.00        19\n",
            "\n",
            "                accuracy                           0.02      1076\n",
            "               macro avg       0.00      0.02      0.00      1076\n",
            "            weighted avg       0.00      0.02      0.00      1076\n",
            "\n",
            "\n",
            "F1-score (Macro) for Task 4: 0.0005\n",
            "Test Loss for Task 4: 4.1246\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Task 4: Embedding from Scratch + LSTM ---\")\n",
        "embedding_dim_scratch = 100 # Chọn một chiều embedding, ví dụ 100 như tài liệu\n",
        "\n",
        "# 1. Xây dựng mô hình\n",
        "lstm_model_scratch = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,           # Kích thước từ vựng\n",
        "        output_dim=embedding_dim_scratch, # Kích thước vector (100)\n",
        "        input_length=max_len            # Độ dài chuỗi (50)\n",
        "        # Không có 'weights', 'trainable=True' là mặc định\n",
        "    ),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "lstm_model_scratch.summary()\n",
        "\n",
        "# 2. Compile, huấn luyện\n",
        "lstm_model_scratch.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nTraining LSTM (Scratch) model...\")\n",
        "history_task4 = lstm_model_scratch.fit(\n",
        "    X_train_pad, y_train_encoded,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_pad, y_val_encoded),\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 3. Đánh giá\n",
        "print(\"\\nEvaluating model (Task 4):\")\n",
        "test_loss_task4, test_acc_task4 = lstm_model_scratch.evaluate(X_test_pad, y_test_encoded)\n",
        "\n",
        "y_pred_prob_task4 = lstm_model_scratch.predict(X_test_pad)\n",
        "y_pred_task4 = np.argmax(y_pred_prob_task4, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report (Task 4):\")\n",
        "print(classification_report(y_test_encoded, y_pred_task4, target_names=class_names))\n",
        "\n",
        "# 4. Lưu kết quả\n",
        "f1_macro_task4 = f1_score(y_test_encoded, y_pred_task4, average='macro')\n",
        "results['LSTM (Scratch)'] = {'F1-score (Macro)': f1_macro_task4, 'Test Loss': test_loss_task4}\n",
        "print(f\"\\nF1-score (Macro) for Task 4: {f1_macro_task4:.4f}\")\n",
        "print(f\"Test Loss for Task 4: {test_loss_task4:.4f}\")"
      ],
      "id": "Lwdc0CDDvobT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Phương pháp\n",
        "\n",
        "* **Embedding layer:** `input_dim = 4265`, `output_dim = 100`, `trainable = True` (mặc định).\n",
        "* **Kiến trúc:** `Embedding → LSTM(128, dropout=0.2, recurrent_dropout=0.2) → Dense(softmax)`.\n",
        "* **Huấn luyện:** 20 epoch, early stopping theo `val_loss`.\n",
        "\n",
        "#### Kết quả\n",
        "\n",
        "* **F1-macro:** 0.0005\n",
        "* **Độ chính xác:** 2.16%\n",
        "* **Test Loss:** 4.1246\n",
        "* Mô hình **chỉ học được duy nhất một lớp (`general_dontcare`)** với recall = 1.0, tất cả các lớp khác có F1 = 0.0.\n",
        "\n",
        "#### Phân tích\n",
        "\n",
        "Kết quả này cho thấy mô hình **gần như không học được gì**, và thậm chí **kém hơn cả mô hình sử dụng Word2Vec đóng băng** ở Task 3.\n",
        "Một số nguyên nhân có thể giải thích:\n",
        "\n",
        "1. **Không có biểu diễn ngữ nghĩa ban đầu:** Embedding học từ đầu cần lượng dữ liệu lớn để hình thành không gian vector có ý nghĩa, trong khi tập HWU (~10k câu, 64 lớp) là quá nhỏ.\n",
        "2. **Dữ liệu mất cân bằng nặng:** Một số intent có ít hơn 10 mẫu, khiến gradient dễ rơi vào cực trị phẳng.\n",
        "3. **Dropout + recurrent_dropout = 0.2** trong bối cảnh dữ liệu nhỏ dẫn đến **mất thông tin tuần tự quan trọng**.\n",
        "4. **Không có pretraining ngữ nghĩa**, LSTM phải tự học vừa biểu diễn từ vừa học ngữ cảnh → **gradient nhiễu và khó hội tụ**.\n",
        "\n",
        "#### Nhận xét\n",
        "\n",
        "Kết quả củng cố nhận định từ Task 3:\n",
        "\n",
        "> “Việc học biểu diễn ngữ nghĩa từ đầu không hiệu quả với dữ liệu hạn chế.”\n",
        "\n",
        "Trong trường hợp này, mô hình **Word2Vec (đóng băng)** còn mang lại biểu diễn ổn định hơn.\n",
        "Đây là minh chứng cho vai trò của **embedding tiền huấn luyện** trong NLP hiện đại — cung cấp nền tảng ngữ nghĩa giúp mô hình hội tụ nhanh và chính xác hơn.\n",
        "\n",
        "➡️ Bước kế tiếp hợp lý là **Task 5 – Embedding tinh chỉnh (Fine-tuned Word2Vec) + BiLSTM**, cho phép vừa tận dụng tri thức tiền huấn luyện vừa thích nghi với ngữ cảnh dữ liệu HWU, nhằm cải thiện rõ rệt F1-macro."
      ],
      "metadata": {
        "id": "FYoOcuonWOjD"
      },
      "id": "FYoOcuonWOjD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpJvxaevvobT"
      },
      "source": [
        "## Nhiệm vụ 5: Đánh giá, So sánh và Phân tích"
      ],
      "id": "lpJvxaevvobT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_-WRp4bvobT"
      },
      "source": [
        "### 1. So sánh định lượng"
      ],
      "id": "T_-WRp4bvobT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvFJqifsvobT",
        "outputId": "5eedc17a-921b-4068-f09b-79170a909ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BẢNG TỔNG KẾT KẾT QUẢ\n",
            "=====================\n",
            "|                    |   F1-score (Macro) | Test Loss          |\n",
            "|:-------------------|-------------------:|:-------------------|\n",
            "| TF-IDF + LR        |             0.8353 | N/A                |\n",
            "| W2V (Avg) + Dense  |             0.1301 | 3.2135283946990967 |\n",
            "| LSTM (Pre-trained) |             0.0513 | 3.4492194652557373 |\n",
            "| LSTM (Scratch)     |             0.0005 | 4.124602317810059  |\n"
          ]
        }
      ],
      "source": [
        "# Tạo bảng so sánh từ dictionary 'results'\n",
        "df_results = pd.DataFrame(results).T\n",
        "\n",
        "# Sắp xếp lại thứ tự hàng cho dễ đọc\n",
        "df_results = df_results.reindex([\n",
        "    'TF-IDF + LR',\n",
        "    'W2V (Avg) + Dense',\n",
        "    'LSTM (Pre-trained)',\n",
        "    'LSTM (Scratch)'\n",
        "])\n",
        "\n",
        "print(\"BẢNG TỔNG KẾT KẾT QUẢ\")\n",
        "print(\"=====================\")\n",
        "# In ra dạng Markdown cho đẹp\n",
        "print(df_results.to_markdown(floatfmt=\".4f\"))"
      ],
      "id": "MvFJqifsvobT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrjYgdUUvobT"
      },
      "source": [
        "### 2. Phân tích định tính"
      ],
      "id": "JrjYgdUUvobT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM-uxAy9vobT",
        "outputId": "991820d2-11cc-43e3-825b-87528c84fd2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PHÂN TÍCH ĐỊNH TÍNH CÁC CÂU KHÓ\n",
            "=================================\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\n",
            "Câu: 'can you remind me to not call my mom'\n",
            "Nhãn thật: reminder_create\n",
            "---\n",
            "  Model 1 (TF-IDF):   calendar_set\n",
            "  Model 2 (W2V Avg):  general_explain\n",
            "  Model 3 (LSTM Pre): qa_factoid\n",
            "  Model 4 (LSTM Scr): general_dontcare\n",
            "\n",
            "Câu: 'is it going to be sunny or rainy tomorrow'\n",
            "Nhãn thật: weather_query\n",
            "---\n",
            "  Model 1 (TF-IDF):   weather_query\n",
            "  Model 2 (W2V Avg):  takeaway_query\n",
            "  Model 3 (LSTM Pre): qa_stock\n",
            "  Model 4 (LSTM Scr): general_dontcare\n",
            "\n",
            "Câu: 'find a flight from new york to london but not through paris'\n",
            "Nhãn thật: flight_search\n",
            "---\n",
            "  Model 1 (TF-IDF):   general_negate\n",
            "  Model 2 (W2V Avg):  takeaway_order\n",
            "  Model 3 (LSTM Pre): transport_taxi\n",
            "  Model 4 (LSTM Scr): general_dontcare\n"
          ]
        }
      ],
      "source": [
        "# Các câu \"khó\" từ tài liệu\n",
        "hard_sentences = [\n",
        "    \"can you remind me to not call my mom\",\n",
        "    \"is it going to be sunny or rainy tomorrow\",\n",
        "    \"find a flight from new york to london but not through paris\"\n",
        "]\n",
        "\n",
        "# Nhãn thật tương ứng (dựa trên PDF)\n",
        "true_intents = [\n",
        "    \"reminder_create\",\n",
        "    \"weather_query\",\n",
        "    \"flight_search\"\n",
        "]\n",
        "\n",
        "print(\"PHÂN TÍCH ĐỊNH TÍNH CÁC CÂU KHÓ\")\n",
        "print(\"=================================\")\n",
        "\n",
        "# --- Chuẩn bị dữ liệu cho từng mô hình ---\n",
        "\n",
        "# Model 1 (TF-IDF)\n",
        "preds_task1 = tfidf_lr_pipeline.predict(hard_sentences)\n",
        "\n",
        "# Model 2 (W2V Avg)\n",
        "hard_sentences_avg = np.array([sentence_to_avg_vector(text, w2v_model, embedding_dim_w2v) for text in hard_sentences])\n",
        "preds_task2_prob = w2v_avg_model.predict(hard_sentences_avg)\n",
        "preds_task2 = np.argmax(preds_task2_prob, axis=1)\n",
        "\n",
        "# Model 3 & 4 (LSTM) - Dùng chung dữ liệu đã xử lý\n",
        "hard_sequences = tokenizer.texts_to_sequences(hard_sentences)\n",
        "hard_padded = pad_sequences(hard_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Model 3 (LSTM Pre-trained)\n",
        "preds_task3_prob = lstm_model_pretrained.predict(hard_padded)\n",
        "preds_task3 = np.argmax(preds_task3_prob, axis=1)\n",
        "\n",
        "# Model 4 (LSTM Scratch)\n",
        "preds_task4_prob = lstm_model_scratch.predict(hard_padded)\n",
        "preds_task4 = np.argmax(preds_task4_prob, axis=1)\n",
        "\n",
        "# --- In kết quả ---\n",
        "for i, sentence in enumerate(hard_sentences):\n",
        "    print(f\"\\nCâu: '{sentence}'\")\n",
        "    print(f\"Nhãn thật: {true_intents[i]}\")\n",
        "    print(\"---\")\n",
        "    # Dùng label_encoder.inverse_transform để lấy lại tên nhãn\n",
        "    print(f\"  Model 1 (TF-IDF):   {label_encoder.inverse_transform([preds_task1[i]])[0]}\")\n",
        "    print(f\"  Model 2 (W2V Avg):  {label_encoder.inverse_transform([preds_task2[i]])[0]}\")\n",
        "    print(f\"  Model 3 (LSTM Pre): {label_encoder.inverse_transform([preds_task3[i]])[0]}\")\n",
        "    print(f\"  Model 4 (LSTM Scr): {label_encoder.inverse_transform([preds_task4[i]])[0]}\")"
      ],
      "id": "PM-uxAy9vobT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧭 Kết luận Tổng thể\n",
        "\n",
        "Qua bốn nhiệm vụ liên tiếp, chuỗi thí nghiệm đã làm sáng tỏ **quá trình tiến hóa của mô hình xử lý ngôn ngữ tự nhiên (NLP)** từ các phương pháp biểu diễn truyền thống đến hướng học sâu hiện đại:\n",
        "\n",
        "| Mô hình    | Loại biểu diễn       | Kiến trúc           | F1-macro   | Nhận xét chính                                                                   |\n",
        "| ---------- | -------------------- | ------------------- | ---------- | -------------------------------------------------------------------------------- |\n",
        "| **Task 1** | TF-IDF               | Logistic Regression | **0.83**   | Hiệu quả cao nhờ đặc trưng tuyến tính, phù hợp với dữ liệu gọn và nhiều lớp.     |\n",
        "| **Task 2** | Word2Vec trung bình  | Logistic Regression | **0.36**   | Giảm mạnh – trung bình vector làm mất ngữ cảnh và thứ tự từ.                     |\n",
        "| **Task 3** | Word2Vec (frozen)    | LSTM                | **0.05**   | LSTM có khả năng học tuần tự nhưng embedding cố định → mô hình không hội tụ tốt. |\n",
        "| **Task 4** | Embedding học từ đầu | LSTM                | **0.0005** | Mất hoàn toàn hiệu năng – không đủ dữ liệu để học biểu diễn ngữ nghĩa từ đầu.    |\n",
        "\n",
        "### 🔍 Tổng kết\n",
        "\n",
        "1. **Các phương pháp thống kê (TF-IDF)** vẫn cực kỳ mạnh trong môi trường dữ liệu nhỏ, đặc biệt khi nhiệm vụ là **phân loại ý định (intent classification)** với ngữ cảnh ngắn.\n",
        "2. **Các mô hình học sâu (LSTM)** chỉ phát huy khi được hỗ trợ bởi **biểu diễn ngữ nghĩa tiền huấn luyện** và **tập dữ liệu đủ lớn** để học ngữ cảnh.\n",
        "3. **Embedding từ đầu không khả thi** trong điều kiện dữ liệu hạn chế — mô hình không thể tự hình thành không gian ngữ nghĩa có cấu trúc.\n",
        "4. Kết quả này tái khẳng định xu hướng của NLP hiện nay: **không thể bỏ qua pretraining**, từ Word2Vec, GloVe cho đến Transformer (BERT, GPT,...)."
      ],
      "metadata": {
        "id": "cR5gCksFWq0q"
      },
      "id": "cR5gCksFWq0q"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}